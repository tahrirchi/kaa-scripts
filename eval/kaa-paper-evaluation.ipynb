{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c5f4f8-de19-4c36-88cf-faf9231289cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebc07b5-28b8-486c-93a8-825203639544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_Latn</th>\n",
       "      <th>kaa_Latn</th>\n",
       "      <th>rus_Cyrl</th>\n",
       "      <th>uzn_Latn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On Monday, scientists from the Stanford Univer...</td>\n",
       "      <td>Dúyshembi kúni Stenford universiteti medicina ...</td>\n",
       "      <td>В понедельник ученые из Медицинской школы Стэн...</td>\n",
       "      <td>Dushanba kuni Stenford Universitetining Tibbiy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead researchers say this may bring early dete...</td>\n",
       "      <td>Jetekshı ilimiy izertlewler tastıyıqlaydi, bul...</td>\n",
       "      <td>Ведущие исследователи утверждают, что он может...</td>\n",
       "      <td>Yetakchi tadqiqotchilarning aytishicha, bu kam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The JAS 39C Gripen crashed onto a runway at ar...</td>\n",
       "      <td>Jas 39 C Gripen shama menen azanǵı saat 9:30 d...</td>\n",
       "      <td>Приблизительно в 9:30 по местному времени (02:...</td>\n",
       "      <td>JAS 39C Gripen mahalliy vaqt bilan ertalab soa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pilot was identified as Squadron Leader Di...</td>\n",
       "      <td>Ushıwshı eskadron jetekshisi Dilokrit Pattavi ...</td>\n",
       "      <td>Личность пилота была установлена. Им оказался ...</td>\n",
       "      <td>Uchuvchi bo'linma rahbari Dilokrit Pattava eka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Local media reports an airport fire vehicle ro...</td>\n",
       "      <td>Jergilikli ǵalaba xabar qurallari xabar beriwi...</td>\n",
       "      <td>Местные СМИ сообщают, что в аэропорту по пути ...</td>\n",
       "      <td>Mahalliy axborot vositalarining xabar berishic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>The tourist season for the hill stations gener...</td>\n",
       "      <td>Hindistan jazı waqtında taw stanciyalari ushin...</td>\n",
       "      <td>Пик туристического сезона в горных деревушках ...</td>\n",
       "      <td>Tog' bekatlari uchun sayyohlik mavsumi odatda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>However, they have a different kind of beauty ...</td>\n",
       "      <td>Bıraq, qısta olardın har qıylı gózzalıqlari há...</td>\n",
       "      <td>Впрочем, зимой это другая красота и шарм, с го...</td>\n",
       "      <td>Shunday bo'lsa-da, ular qish vaqtida o'zgacha ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Only a few airlines still offer bereavement fa...</td>\n",
       "      <td>Tek ǵana ayrim aviakompaniyalar elege shekem a...</td>\n",
       "      <td>Только несколько авиакомпаний всё еще предлага...</td>\n",
       "      <td>Faqat bir nechta aviakompaniya hali ham yaqin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Airlines that offer these include Air Canada, ...</td>\n",
       "      <td>Bul usınıslardı usınıs etetinler Air Canada, D...</td>\n",
       "      <td>Авиакомпании, предлагающие эти услуги включают...</td>\n",
       "      <td>Bularni taklif qiluvchi aviakompaniyalarga Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>In all cases, you must book by phone directly ...</td>\n",
       "      <td>Barlıq jaǵdaylarda, siz aviakompaniya menen tu...</td>\n",
       "      <td>В любом случае вы должны бронировать билеты по...</td>\n",
       "      <td>Barcha hollarda siz aviakompaniyaga bevosita t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              eng_Latn  \\\n",
       "0    On Monday, scientists from the Stanford Univer...   \n",
       "1    Lead researchers say this may bring early dete...   \n",
       "2    The JAS 39C Gripen crashed onto a runway at ar...   \n",
       "3    The pilot was identified as Squadron Leader Di...   \n",
       "4    Local media reports an airport fire vehicle ro...   \n",
       "..                                                 ...   \n",
       "992  The tourist season for the hill stations gener...   \n",
       "993  However, they have a different kind of beauty ...   \n",
       "994  Only a few airlines still offer bereavement fa...   \n",
       "995  Airlines that offer these include Air Canada, ...   \n",
       "996  In all cases, you must book by phone directly ...   \n",
       "\n",
       "                                              kaa_Latn  \\\n",
       "0    Dúyshembi kúni Stenford universiteti medicina ...   \n",
       "1    Jetekshı ilimiy izertlewler tastıyıqlaydi, bul...   \n",
       "2    Jas 39 C Gripen shama menen azanǵı saat 9:30 d...   \n",
       "3    Ushıwshı eskadron jetekshisi Dilokrit Pattavi ...   \n",
       "4    Jergilikli ǵalaba xabar qurallari xabar beriwi...   \n",
       "..                                                 ...   \n",
       "992  Hindistan jazı waqtında taw stanciyalari ushin...   \n",
       "993  Bıraq, qısta olardın har qıylı gózzalıqlari há...   \n",
       "994  Tek ǵana ayrim aviakompaniyalar elege shekem a...   \n",
       "995  Bul usınıslardı usınıs etetinler Air Canada, D...   \n",
       "996  Barlıq jaǵdaylarda, siz aviakompaniya menen tu...   \n",
       "\n",
       "                                              rus_Cyrl  \\\n",
       "0    В понедельник ученые из Медицинской школы Стэн...   \n",
       "1    Ведущие исследователи утверждают, что он может...   \n",
       "2    Приблизительно в 9:30 по местному времени (02:...   \n",
       "3    Личность пилота была установлена. Им оказался ...   \n",
       "4    Местные СМИ сообщают, что в аэропорту по пути ...   \n",
       "..                                                 ...   \n",
       "992  Пик туристического сезона в горных деревушках ...   \n",
       "993  Впрочем, зимой это другая красота и шарм, с го...   \n",
       "994  Только несколько авиакомпаний всё еще предлага...   \n",
       "995  Авиакомпании, предлагающие эти услуги включают...   \n",
       "996  В любом случае вы должны бронировать билеты по...   \n",
       "\n",
       "                                              uzn_Latn  \n",
       "0    Dushanba kuni Stenford Universitetining Tibbiy...  \n",
       "1    Yetakchi tadqiqotchilarning aytishicha, bu kam...  \n",
       "2    JAS 39C Gripen mahalliy vaqt bilan ertalab soa...  \n",
       "3    Uchuvchi bo'linma rahbari Dilokrit Pattava eka...  \n",
       "4    Mahalliy axborot vositalarining xabar berishic...  \n",
       "..                                                 ...  \n",
       "992  Tog' bekatlari uchun sayyohlik mavsumi odatda ...  \n",
       "993  Shunday bo'lsa-da, ular qish vaqtida o'zgacha ...  \n",
       "994  Faqat bir nechta aviakompaniya hali ham yaqin ...  \n",
       "995  Bularni taklif qiluvchi aviakompaniyalarga Air...  \n",
       "996  Barcha hollarda siz aviakompaniyaga bevosita t...  \n",
       "\n",
       "[997 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_translations(lang):\n",
    "    with open(f'dataset/flores-dev/{lang}.dev', 'r') as fp:\n",
    "        data = fp.read()\n",
    "    sents = data.split('\\n')\n",
    "    sents = [sent for sent in sents if sent != '']\n",
    "    return sents\n",
    "\n",
    "df_dev = pd.DataFrame({\n",
    "    'eng_Latn': extract_translations('eng_Latn'),\n",
    "    'kaa_Latn': extract_translations('kaa_Latn'),\n",
    "    'rus_Cyrl': extract_translations('rus_Cyrl'),\n",
    "    'uzn_Latn': extract_translations('uzn_Latn')})\n",
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d1b181-965b-484b-a74b-bf980f120b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_Latn</th>\n",
       "      <th>kaa_Latn</th>\n",
       "      <th>rus_Cyrl</th>\n",
       "      <th>uzn_Latn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"We now have 4-month-old mice that are non-dia...</td>\n",
       "      <td>\"Házir bizde aldın diabetke shalınǵan, biraq h...</td>\n",
       "      <td>\"Теперь у нас есть четырёхмесячные мыши, у кот...</td>\n",
       "      <td>\"Hozir bizda diabetik bo'lishi kerak bo'lgan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Ehud Ur, professor of medicine at Dalhousi...</td>\n",
       "      <td>Jańa Shotlandiya, Galifaks qalasındaǵı Dalxauz...</td>\n",
       "      <td>Согласно предупреждению доктора Эхуда Ура (Ehu...</td>\n",
       "      <td>Yangi Shotlandiyaning Galifaks shahridagi Dalx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Like some other experts, he is skeptical about...</td>\n",
       "      <td>Basqa qánigeler sıyaqlı, ol bul tabılǵan zatla...</td>\n",
       "      <td>Как и некоторые другие эксперты, он сомневаетс...</td>\n",
       "      <td>Ayrim boshqa mutaxassislar kabi, u diabetni da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Monday, Sara Danius, permanent secretary of...</td>\n",
       "      <td>Dúyshembi kúni Shvetsiya akademiyası Ádebiyat ...</td>\n",
       "      <td>В понедельник Сара Даниус, постоянный секретар...</td>\n",
       "      <td>Dushanba kuni Shvetsiya Fanlar akademiyasi ada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Danius said, \"Right now we are doing nothing. ...</td>\n",
       "      <td>Danius bılay dedi: \"Házir biz heshnárse islep ...</td>\n",
       "      <td>Даниус заявил: \"Сейчас мы ничего не делаем. Я ...</td>\n",
       "      <td>Danius \"Biz hozirda hech nima qilmayapmiz. Men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>As the areas are sparsely populated, and light...</td>\n",
       "      <td>Aymaqlar kem xalıq jasaytuǵınlıǵı hám jaqtılıq...</td>\n",
       "      <td>Так как эти районы являются малонаселенными, и...</td>\n",
       "      <td>Hududlarda aholi siyrakligi tufayli, yorug'lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Japanese work culture is more hierarchical and...</td>\n",
       "      <td>Yapon miynet mádeniyatı batıs táreplikler úyre...</td>\n",
       "      <td>Японская культура труда иерархичнее и формальн...</td>\n",
       "      <td>Yaponlarning ishlash madaniyati g'arbliklar od...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Suits are standard business attire, and cowork...</td>\n",
       "      <td>Kostyumlar standart jumıs kiyimi bolıp tabılad...</td>\n",
       "      <td>Костюмы являются стандартной деловой одеждой, ...</td>\n",
       "      <td>Kostyum-shimlar standart ish kiyimidir, hamkas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>Workplace harmony is crucial, emphasizing grou...</td>\n",
       "      <td>Jumıs jayındaǵı uyqaslıq sheshiwshi áhmiyetke ...</td>\n",
       "      <td>Чрезвычайно важна гармония на рабочем месте, а...</td>\n",
       "      <td>Alohida shaxslarning yutuqlarini maqtashdan ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Workers must often get their superiors' approv...</td>\n",
       "      <td>Jumısshılar kóbinese ózleri qabıl etetuǵın hár...</td>\n",
       "      <td>Обычно работники должны получить разрешение на...</td>\n",
       "      <td>Ishshilar ko'pincha o'zlari qabiladigan har qa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               eng_Latn  \\\n",
       "0     \"We now have 4-month-old mice that are non-dia...   \n",
       "1     Dr. Ehud Ur, professor of medicine at Dalhousi...   \n",
       "2     Like some other experts, he is skeptical about...   \n",
       "3     On Monday, Sara Danius, permanent secretary of...   \n",
       "4     Danius said, \"Right now we are doing nothing. ...   \n",
       "...                                                 ...   \n",
       "1007  As the areas are sparsely populated, and light...   \n",
       "1008  Japanese work culture is more hierarchical and...   \n",
       "1009  Suits are standard business attire, and cowork...   \n",
       "1010  Workplace harmony is crucial, emphasizing grou...   \n",
       "1011  Workers must often get their superiors' approv...   \n",
       "\n",
       "                                               kaa_Latn  \\\n",
       "0     \"Házir bizde aldın diabetke shalınǵan, biraq h...   \n",
       "1     Jańa Shotlandiya, Galifaks qalasındaǵı Dalxauz...   \n",
       "2     Basqa qánigeler sıyaqlı, ol bul tabılǵan zatla...   \n",
       "3     Dúyshembi kúni Shvetsiya akademiyası Ádebiyat ...   \n",
       "4     Danius bılay dedi: \"Házir biz heshnárse islep ...   \n",
       "...                                                 ...   \n",
       "1007  Aymaqlar kem xalıq jasaytuǵınlıǵı hám jaqtılıq...   \n",
       "1008  Yapon miynet mádeniyatı batıs táreplikler úyre...   \n",
       "1009  Kostyumlar standart jumıs kiyimi bolıp tabılad...   \n",
       "1010  Jumıs jayındaǵı uyqaslıq sheshiwshi áhmiyetke ...   \n",
       "1011  Jumısshılar kóbinese ózleri qabıl etetuǵın hár...   \n",
       "\n",
       "                                               rus_Cyrl  \\\n",
       "0     \"Теперь у нас есть четырёхмесячные мыши, у кот...   \n",
       "1     Согласно предупреждению доктора Эхуда Ура (Ehu...   \n",
       "2     Как и некоторые другие эксперты, он сомневаетс...   \n",
       "3     В понедельник Сара Даниус, постоянный секретар...   \n",
       "4     Даниус заявил: \"Сейчас мы ничего не делаем. Я ...   \n",
       "...                                                 ...   \n",
       "1007  Так как эти районы являются малонаселенными, и...   \n",
       "1008  Японская культура труда иерархичнее и формальн...   \n",
       "1009  Костюмы являются стандартной деловой одеждой, ...   \n",
       "1010  Чрезвычайно важна гармония на рабочем месте, а...   \n",
       "1011  Обычно работники должны получить разрешение на...   \n",
       "\n",
       "                                               uzn_Latn  \n",
       "0     \"Hozir bizda diabetik bo'lishi kerak bo'lgan, ...  \n",
       "1     Yangi Shotlandiyaning Galifaks shahridagi Dalx...  \n",
       "2     Ayrim boshqa mutaxassislar kabi, u diabetni da...  \n",
       "3     Dushanba kuni Shvetsiya Fanlar akademiyasi ada...  \n",
       "4     Danius \"Biz hozirda hech nima qilmayapmiz. Men...  \n",
       "...                                                 ...  \n",
       "1007  Hududlarda aholi siyrakligi tufayli, yorug'lik...  \n",
       "1008  Yaponlarning ishlash madaniyati g'arbliklar od...  \n",
       "1009  Kostyum-shimlar standart ish kiyimidir, hamkas...  \n",
       "1010  Alohida shaxslarning yutuqlarini maqtashdan ko...  \n",
       "1011  Ishshilar ko'pincha o'zlari qabiladigan har qa...  \n",
       "\n",
       "[1012 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_translations(lang):\n",
    "    with open(f'dataset/flores-test/{lang}.devtest', 'r') as fp:\n",
    "        data = fp.read()\n",
    "    sents = data.split('\\n')\n",
    "    sents = [sent for sent in sents if sent != '']\n",
    "    return sents\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'eng_Latn': extract_translations('eng_Latn'),\n",
    "    'kaa_Latn': extract_translations('kaa_Latn'),\n",
    "    'rus_Cyrl': extract_translations('rus_Cyrl'),\n",
    "    'uzn_Latn': extract_translations('uzn_Latn')})\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9142a21-66c7-4d28-a020-e53012adc924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "mpn = MosesPunctNormalizer(lang=\"en\")\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = text\n",
    "    clean = clean.replace(\"<«\", \"«\")\n",
    "    clean = clean.replace(\">»\", \"»\")\n",
    "        \n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "\n",
    "    clean = re.sub(r'(?=-\\s-)-', \"\", clean) \n",
    "    clean = re.sub(r' {2,}', ' ', clean)\n",
    "    \n",
    "    clean = clean.strip()\n",
    "    return clean\n",
    "\n",
    "for lang in ['eng_Latn', 'kaa_Latn', 'rus_Cyrl', 'uzn_Latn']:\n",
    "    df_dev[lang] = df_dev[lang].apply(preproc)\n",
    "    df_test[lang] = df_test[lang].apply(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b2ac16-f239-4d34-91f4-197ac5bbe2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('dataset/flores-dev.csv', index=False)\n",
    "df_test.to_csv('dataset/flores-test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa5fe9-9c74-41d4-b3e3-faec951ad234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# apertium-uzb-kaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287950d1-e55b-46ba-bb80-13f3c8b3bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('flores-dev.csv')\n",
    "df_test = pd.read_csv('flores-test.csv')\n",
    "len(df_dev), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794601a-534e-4b9d-8acf-90121fdc2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "lang_mapping = {\n",
    "    'kaa_Latn' : 'kaa',\n",
    "    'uzn_Latn' : 'uzb'\n",
    "}\n",
    "\n",
    "def translate(text, src_lang, tgt_lang):\n",
    "    src_lang = lang_mapping[src_lang]\n",
    "    tgt_lang = lang_mapping[tgt_lang]\n",
    "\n",
    "    # Get the current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    cmd = ['apertium', '-d', current_dir, f\"{src_lang}-{tgt_lang}\"]\n",
    "    process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate(input=text.encode())\n",
    "    \n",
    "    try:\n",
    "        cleaned_output = re.sub(r'[*#]', '', stdout.decode().strip())\n",
    "        return cleaned_output\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "translate(\"Yaponiya Markaziy Osiyoga nega qiziqmoqda? Tahlilchilar bilan suhbat\", 'uzn_Latn', 'kaa_Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb333e61-c3b7-4b2b-8c78-23d3c1808304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "translation_pairs = [\n",
    "    ('kaa_Latn', 'uzn_Latn'),\n",
    "    ('uzn_Latn', 'kaa_Latn')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    \n",
    "    translations_dev =[] \n",
    "    for sent in tqdm(source_sentences_dev):\n",
    "        translations_dev.append(translate(sent, src_lang=src_lang, tgt_lang=tgt_lang))\n",
    "\n",
    "    translations_test =[] \n",
    "    for sent in tqdm(source_sentences_test):\n",
    "        translations_test.append(translate(sent, src_lang=src_lang, tgt_lang=tgt_lang))\n",
    "\n",
    "    translations_dev = [preproc(_) for _ in translations_dev if isinstance(_, str)]\n",
    "    translations_test = [preproc(_) for _ in translations_test if isinstance(_, str)]\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dce03f-9fef-4a3c-8a57-1f2f636631a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/apertium-uzb-kaa.csv', index=False)\n",
    "df_test.to_csv('results/test/apertium-uzb-kaa.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db2a89-06b5-4e25-8ac4-c5bb60bc671b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73110d07-0997-4a3e-814a-2914d9349e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 1012)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('dataset/flores-dev.csv')\n",
    "df_test = pd.read_csv('dataset/flores-test.csv')\n",
    "len(df_dev), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1025fa8-5b42-4c86-a111-518c5e783f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from google.cloud import translate_v2 as translate\n",
    "\n",
    "lang_mapping = {\n",
    "    'eng_Latn' : 'en',\n",
    "    'kaa_Latn' : 'kaa',\n",
    "    'rus_Cyrl' : 'ru',\n",
    "    'uzn_Latn' : 'uz',\n",
    "    'kaz_Cyrl' : 'kk'\n",
    "}\n",
    "\n",
    "def translate_google(text, src_lang, tgt_lang, mandatory_src_lang=None) -> str:\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if mandatory_src_lang:\n",
    "        src_lang = lang_mapping[mandatory_src_lang]\n",
    "    else:\n",
    "        src_lang = lang_mapping[src_lang]\n",
    "        \n",
    "    tgt_lang = lang_mapping[tgt_lang]\n",
    "\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    result = translate_client.translate(text, source_language=src_lang, target_language=tgt_lang)\n",
    "\n",
    "    return result[\"translatedText\"]\n",
    "\n",
    "translate_google('Mening ismim Abror', 'kaa_Latn', 'eng_Latn', mandatory_src_lang='uzn_Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8de5e76-327d-46e4-8afd-9aac004d1e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That said, it&#39;s possible to use Wi-Fi.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_google(\"Onıń aytıwınsha, ol Wi-Fi arqalı quwatlanatuǵın esik qońırawın jaratqan.\",  'kaa_Latn', 'eng_Latn', mandatory_src_lang='uzn_Latn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e16626-335c-4f95-b764-59030bd9987f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## from Uzbek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941e5b3-064d-42fc-9f54-50b3de3cdc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "translation_pairs = [\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    \n",
    "    translations_dev =[] \n",
    "    for sent in tqdm(source_sentences_dev):\n",
    "        translations_dev.append(translate_google(sent, src_lang, tgt_lang, 'uzn_Latn'))\n",
    "\n",
    "    translations_test =[] \n",
    "    for sent in tqdm(source_sentences_test):\n",
    "        translations_test.append(translate_google(sent, src_lang, tgt_lang, 'uzn_Latn'))\n",
    "\n",
    "    translations_dev = [preproc(_) for _ in translations_dev if isinstance(_, str)]\n",
    "    translations_test = [preproc(_) for _ in translations_test if isinstance(_, str)]\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade9c5c-e51e-4b97-b2a9-31053e267d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/google-from_uzb.csv', index=False)\n",
    "df_test.to_csv('results/test/google-from_uzb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43948062-0ef7-49a0-85e3-4018ac94c4e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## from Kazakh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7902565-c9df-41a4-9536-fdfb8750752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "translation_pairs = [\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    \n",
    "    translations_dev =[] \n",
    "    for sent in tqdm(source_sentences_dev):\n",
    "        translations_dev.append(translate_google(sent, src_lang, tgt_lang, 'kaz_Cyrl'))\n",
    "\n",
    "    translations_test =[] \n",
    "    for sent in tqdm(source_sentences_test):\n",
    "        translations_test.append(translate_google(sent, src_lang, tgt_lang, 'kaz_Cyrl'))\n",
    "\n",
    "    translations_dev = [preproc(_) for _ in translations_dev if isinstance(_, str)]\n",
    "    translations_test = [preproc(_) for _ in translations_test if isinstance(_, str)]\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c00551-7e9d-4e53-8775-fc2bde4378b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/google-from_kaz.csv', index=False)\n",
    "df_test.to_csv('results/test/google-from_kaz.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa07535-23c9-461a-90d7-cffb99ea7e11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# seq2seq models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de4b348-5f32-457d-9ec1-3940301ac72a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def translate_batch(model, tokenizer, texts, src_lang='uzn_Latn', tgt_lang='kaa_Latn', \n",
    "                    mandatory_src_lang=None, a=32, b=3, max_input_length=256, num_beams=5, \n",
    "                    batch_size=16, **kwargs):\n",
    "    if mandatory_src_lang:\n",
    "        tokenizer.src_lang = mandatory_src_lang\n",
    "    else:\n",
    "        tokenizer.src_lang = src_lang\n",
    "        \n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    \n",
    "    all_translations = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=max_input_length)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs.to(model.device),\n",
    "                forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "                max_new_tokens=int(a + b * inputs.input_ids.shape[1]),\n",
    "                num_beams=num_beams,\n",
    "                num_return_sequences=1,\n",
    "                output_scores=True,\n",
    "                **kwargs\n",
    "            )\n",
    "        \n",
    "        translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        all_translations.extend(translations)\n",
    "\n",
    "    all_translations = [preproc(_) for _ in all_translations]\n",
    "    \n",
    "    return all_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d1432-86ae-4e2c-a2a7-22d6a51ba418",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## nllb-200-distilled-600M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f546b9-a5b5-4d99-974e-fdfd429ce639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_ckpt = 'facebook/nllb-200-distilled-600M'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
    "model.to('cuda')\n",
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aeca1b-592e-40d9-be10-cdac041b75ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### from Uzbek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b930b-aff2-48d8-9402-a6fe9c0ad14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('dataset/flores-dev.csv')\n",
    "df_test = pd.read_csv('dataset/flores-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6ae7bc-62e1-41be-94f8-af07edb11b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to eng_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [03:02<00:00,  2.89s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [03:18<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to rus_Cyrl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [03:13<00:00,  3.07s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [03:45<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to uzn_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [04:35<00:00,  4.38s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [05:30<00:00,  5.16s/it]\n"
     ]
    }
   ],
   "source": [
    "translation_pairs = [\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl'),\n",
    "    ('kaa_Latn', 'uzn_Latn')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    translations_dev = translate_batch(model, tokenizer, source_sentences_dev, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, mandatory_src_lang='uzn_Latn', batch_size=16)\n",
    "    translations_test = translate_batch(model, tokenizer, source_sentences_test, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, mandatory_src_lang='uzn_Latn', batch_size=16)\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f18852-1556-444f-83ab-12176ad7ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/nllb-200-distilled-600M-from_uzb.csv', index=False)\n",
    "df_test.to_csv('results/test/nllb-200-distilled-600M-from_uzb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045e912-c960-4ca4-bbd4-3eff14cab2b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### from Kazakh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30632a16-2293-47c0-b982-ff4daccb7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('dataset/flores-dev.csv')\n",
    "df_test = pd.read_csv('dataset/flores-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d843485-8ec6-4bd7-881d-ddea758a922b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to eng_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [04:12<00:00,  4.00s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [04:34<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to rus_Cyrl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [04:41<00:00,  4.47s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [05:16<00:00,  4.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to uzn_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [03:09<00:00,  3.01s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [04:34<00:00,  4.28s/it]\n"
     ]
    }
   ],
   "source": [
    "translation_pairs = [\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl'),\n",
    "    ('kaa_Latn', 'uzn_Latn')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    translations_dev = translate_batch(model, tokenizer, source_sentences_dev, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, mandatory_src_lang='kaz_Cyrl', batch_size=16)\n",
    "    translations_test = translate_batch(model, tokenizer, source_sentences_test, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, mandatory_src_lang='kaz_Cyrl', batch_size=16)\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aabecc9b-24c6-459f-828c-504e74a14e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/nllb-200-distilled-600M-from_kaz.csv', index=False)\n",
    "df_test.to_csv('results/test/nllb-200-distilled-600M-from_kaz.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a437a-ea1d-4c7a-92e6-3926c0c3bd96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## dilmash-600M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633f6ea0-37e4-48c7-8ead-5b231899a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_ckpt = 'models/dilmash-600M/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
    "model.to('cuda')\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e87e8bff-5289-4961-88ea-0a9293c5eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('dataset/flores-dev.csv')\n",
    "df_test = pd.read_csv('dataset/flores-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d68637-12fe-4504-8a18-d1713fcf5b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from eng_Latn to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [02:04<00:00,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [02:17<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from rus_Cyrl to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [02:08<00:00,  2.03s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [02:18<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from uzn_Latn to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:56<00:00,  1.85s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [02:04<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to eng_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:30<00:00,  1.43s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [01:38<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to rus_Cyrl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:53<00:00,  1.81s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [01:54<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to uzn_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:51<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [01:59<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "translation_pairs = [\n",
    "    ('eng_Latn', 'kaa_Latn'),\n",
    "    ('rus_Cyrl', 'kaa_Latn'),\n",
    "    ('uzn_Latn', 'kaa_Latn'),\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl'),\n",
    "    ('kaa_Latn', 'uzn_Latn')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    translations_dev = translate_batch(model, tokenizer, source_sentences_dev, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, batch_size=16)\n",
    "    translations_test = translate_batch(model, tokenizer, source_sentences_test, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, batch_size=16)\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "794f86ac-be72-4a04-9f36-2e4c3286b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/dilmash-600M.csv', index=False)\n",
    "df_test.to_csv('results/test/dilmash-600M.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8894e3-45f7-4928-b36e-b612e9c25a73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## dilmash-600M-til"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fef46ace-c97b-4dce-b001-fe63084f872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_ckpt = 'models/dilmash-600M-til/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
    "model.to('cuda')\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "233694c3-16af-4f4a-abc5-4a4a52cf5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('dataset/flores-dev.csv')\n",
    "df_test = pd.read_csv('dataset/flores-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0057e8ee-0eff-4308-9fb1-b84731f0812e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from eng_Latn to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:52<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [02:00<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from rus_Cyrl to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [02:02<00:00,  1.94s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [02:09<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from uzn_Latn to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:53<00:00,  1.80s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [02:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to eng_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:29<00:00,  1.43s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [01:35<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to rus_Cyrl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:51<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [01:57<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to uzn_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [01:51<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 64/64 [01:59<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "translation_pairs = [\n",
    "    ('eng_Latn', 'kaa_Latn'),\n",
    "    ('rus_Cyrl', 'kaa_Latn'),\n",
    "    ('uzn_Latn', 'kaa_Latn'),\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl'),\n",
    "    ('kaa_Latn', 'uzn_Latn')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    translations_dev = translate_batch(model, tokenizer, source_sentences_dev, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, batch_size=16)\n",
    "    translations_test = translate_batch(model, tokenizer, source_sentences_test, src_lang=src_lang, \n",
    "                                       tgt_lang=tgt_lang, batch_size=16)\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "494f2c5e-ca0d-44e3-bcb0-454c4d544b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/dilmash-600M-til.csv', index=False)\n",
    "df_test.to_csv('results/test/dilmash-600M-til.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b2d96f-b1f5-4110-a98d-a6a74bf39622",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# claude-3.5-sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c29ef20-77b4-4425-804d-0930a7389222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to him, he created a doorbell that is powered by Wi-Fi.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anthropic import AnthropicVertex\n",
    "\n",
    "client = AnthropicVertex(region='us-east5', project_id=\"glass-scanner-381306\")\n",
    "\n",
    "lang_mapping = {\n",
    "    'eng_Latn': 'English',\n",
    "    'kaa_Latn': 'Karakalpak',\n",
    "    'rus_Cyrl': 'Russian',\n",
    "    'uzn_Latn': 'Uzbek',\n",
    "}\n",
    "\n",
    "def translate_claude(sentence, src_lang, tgt_lang):\n",
    "    src_lang = lang_mapping[src_lang]\n",
    "    tgt_lang = lang_mapping[tgt_lang]\n",
    "\n",
    "    prompt = f\"\"\"You are a professional translator specializing in {src_lang} to {tgt_lang} translations. Your task is to translate the given {src_lang} text into {tgt_lang} with the highest level of accuracy, preserving the original meaning and context. Use proper grammar, punctuation, and idiomatic expressions appropriate for {tgt_lang} speakers. Do not include any additional explanations or commentary; provide only the translated text.\n",
    "    {src_lang}: {sentence}\n",
    "    {tgt_lang}:\n",
    "    \"\"\"\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model = \"claude-3-5-sonnet@20240620\",\n",
    "        max_tokens=4096,\n",
    "        temperature=1,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return message.content[0].text\n",
    "\n",
    "translate_claude(\"Onıń aytıwınsha, ol Wi-Fi arqalı quwatlanatuǵın esik qońırawın jaratqan.\",  'kaa_Latn', 'eng_Latn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c53a4e44-7702-48d8-afa9-87dbdf841332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 1012)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('dataset/flores-dev.csv')\n",
    "df_test = pd.read_csv('dataset/flores-test.csv')\n",
    "len(df_dev), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1a0b7-38e1-4954-bb2a-faca82262d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "translation_pairs = [\n",
    "    ('eng_Latn', 'kaa_Latn'),\n",
    "    ('rus_Cyrl', 'kaa_Latn'),\n",
    "    ('uzn_Latn', 'kaa_Latn'),\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl'),\n",
    "    ('kaa_Latn', 'uzn_Latn')\n",
    "]\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences_dev = df_dev[src_lang].tolist()\n",
    "    source_sentences_test = df_test[src_lang].tolist()\n",
    "    \n",
    "    translations_dev =[] \n",
    "    for sent in tqdm(source_sentences_dev):\n",
    "        translations_dev.append(translate_claude(sent, src_lang, tgt_lang))\n",
    "\n",
    "    translations_test =[] \n",
    "    for sent in tqdm(source_sentences_test):\n",
    "        translations_test.append(translate_claude(sent, src_lang, tgt_lang))\n",
    "\n",
    "    translations_dev = [preproc(_) for _ in translations_dev if isinstance(_, str)]\n",
    "    translations_test = [preproc(_) for _ in translations_test if isinstance(_, str)]\n",
    "    \n",
    "    # Add translations to the DataFrame with the appropriate column name\n",
    "    df_dev[f\"{src_lang}-{tgt_lang}\"] = translations_dev\n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f795f-46fa-4eb3-b38d-57b1f422d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv('results/dev/claude-3-5-sonnet.csv', index=False)\n",
    "df_test.to_csv('results/test/claude-3-5-sonnet.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63090c58",
   "metadata": {},
   "source": [
    "# tilmoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c013a990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 1012)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_csv('dataset/flores-dev.csv')\n",
    "df_test = pd.read_csv('dataset/flores-test.csv')\n",
    "\n",
    "len(df_dev), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503633c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import typing as tp\n",
    "import unicodedata\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "\n",
    "# this code is adapted from  the Stopes repo of the NLLB team\n",
    "# https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/monolingual/monolingual_line_processor.py#L214\n",
    "mpn = MosesPunctNormalizer(lang=\"en\")\n",
    "mpn.substitutions = [\n",
    "    (re.compile(r), sub) for r, sub in mpn.substitutions\n",
    "]\n",
    "\n",
    "\n",
    "def get_non_printing_char_replacer(replace_by: str = \" \") -> tp.Callable[[str], str]:\n",
    "    non_printable_map = {\n",
    "        ord(c): replace_by\n",
    "        for c in (chr(i) for i in range(sys.maxunicode + 1))\n",
    "        # same as \\p{C} in perl\n",
    "        # see https://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "        if unicodedata.category(c) in {\"C\", \"Cc\", \"Cf\", \"Cs\", \"Co\", \"Cn\"}\n",
    "    }\n",
    "\n",
    "    def replace_non_printing_char(line) -> str:\n",
    "        return line.translate(non_printable_map)\n",
    "\n",
    "    return replace_non_printing_char\n",
    "\n",
    "replace_nonprint = get_non_printing_char_replacer(\" \")\n",
    "\n",
    "def preproc(text):\n",
    "    clean = text\n",
    "    clean = clean.replace(\"<«\", \"«\")\n",
    "    clean = clean.replace(\">»\", \"»\")\n",
    "        \n",
    "    clean = mpn.normalize(text)\n",
    "    clean = replace_nonprint(clean)\n",
    "    # replace 𝓕𝔯𝔞𝔫𝔠𝔢𝔰𝔠𝔞 by Francesca\n",
    "    clean = unicodedata.normalize(\"NFKC\", clean)\n",
    "\n",
    "    clean = re.sub(r'(?=-\\s-)-', \"\", clean) \n",
    "    clean = re.sub(r' {2,}', ' ', clean)\n",
    "    \n",
    "    clean = clean.strip()\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944baabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"text\": {\n",
    "        \"texts\": [\n",
    "            separator.join(df_test['uzn_Latn'].tolist()[:30])\n",
    "        ]\n",
    "    },\n",
    "    \"source_lang\": 'uzn_Latn',\n",
    "    \"target_lang\": 'kaa_Latn'\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "result = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f7c6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_translation = \"\"\n",
    "all_translations = []\n",
    "\n",
    "for snippet in result['sentences']:\n",
    "    if separator.strip() in snippet['text']:\n",
    "        all_translations.append(current_translation.strip())\n",
    "        current_translation = \"\"\n",
    "    else:\n",
    "        current_translation += ' '+snippet['translated']\n",
    "\n",
    "all_translations.append(current_translation.strip())\n",
    "len(all_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045770a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prefix': ' ',\n",
       " 'text': \"Olimlarning aytishicha, mazkur hayvonning ustki patlari kashtan-jigarrang, pastkilari esa och yoki karatenoid rangda bo'lgan.Mening ismim.Topilma qushlardagi patlar evolyutsiyasi to'g'risida ham tushuncha beradi.\",\n",
       " 'translated': 'Ilimpazlardıń aytıwınsha, usı haywannıń ústingi párleri kashtan-qońır, tómengileri bolsa ashıq yamasa karatenoid reńde bolgan.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02184c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb986a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# API endpoint\n",
    "url = \"https://websocket.tahrirchi.uz/translate\"\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    \"Authorization\": \"389eebc7-4e87-4c59-b0c0-d1a1f1c0aacc\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "separator = ' Mening ismim. '\n",
    "\n",
    "def separate_translations(result):\n",
    "    current_translation = \"\"\n",
    "    all_translations = []\n",
    "\n",
    "    for snippet in result['sentences']:\n",
    "        if separator.strip() in snippet['text']:\n",
    "            all_translations.append(current_translation.strip())\n",
    "            current_translation = \"\"\n",
    "        else:\n",
    "            current_translation += ' '+snippet['translated']\n",
    "\n",
    "    all_translations.append(current_translation.strip())\n",
    "    return all_translations\n",
    "\n",
    "def translate_tilmoch(texts, src_lang, tgt_lang):\n",
    "    # Request payload\n",
    "    payload = {\n",
    "        \"text\": {\n",
    "            \"texts\": [\n",
    "                separator.join(texts)\n",
    "            ]\n",
    "        },\n",
    "        \"source_lang\": src_lang,\n",
    "        \"target_lang\": tgt_lang\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        result = response.json()\n",
    "        translated_texts = separate_translations(result)\n",
    "        \n",
    "        if len(translated_texts)==len(texts):\n",
    "            return translated_texts\n",
    "        else:\n",
    "            print('skill issue')\n",
    "            print(len(translated_texts))\n",
    "            return [None]*len(texts)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e84b51f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from eng_Latn to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:16<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from rus_Cyrl to kaa_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:32<00:00,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to eng_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:03<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating from kaa_Latn to rus_Cyrl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:12<00:00,  3.91s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "translation_pairs = [\n",
    "    ('eng_Latn', 'kaa_Latn'),\n",
    "    ('rus_Cyrl', 'kaa_Latn'),\n",
    "    # ('uzn_Latn', 'kaa_Latn'),\n",
    "    ('kaa_Latn', 'eng_Latn'),\n",
    "    ('kaa_Latn', 'rus_Cyrl'),\n",
    "    # ('kaa_Latn', 'uzn_Latn')\n",
    "]\n",
    "\n",
    "batch_size = 30\n",
    "\n",
    "# Perform translations for each pair\n",
    "for src_lang, tgt_lang in translation_pairs:\n",
    "    print(f\"Translating from {src_lang} to {tgt_lang}\")\n",
    "    \n",
    "    source_sentences = df_test[src_lang].tolist()\n",
    "\n",
    "    translations = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(source_sentences), batch_size)):\n",
    "        texts = source_sentences[i:i+batch_size]\n",
    "        trns = translate_tilmoch(texts, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "        trns = [preproc(trn) for trn in trns if trn is not None]\n",
    "        translations.extend(trns)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    df_test[f\"{src_lang}-{tgt_lang}\"] = translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58ef435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_Latn</th>\n",
       "      <th>kaa_Latn</th>\n",
       "      <th>rus_Cyrl</th>\n",
       "      <th>uzn_Latn</th>\n",
       "      <th>uzn_Latn-kaa_Latn</th>\n",
       "      <th>kaa_Latn-uzn_Latn</th>\n",
       "      <th>eng_Latn-kaa_Latn</th>\n",
       "      <th>rus_Cyrl-kaa_Latn</th>\n",
       "      <th>kaa_Latn-eng_Latn</th>\n",
       "      <th>kaa_Latn-rus_Cyrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"We now have 4-month-old mice that are non-dia...</td>\n",
       "      <td>\"Házir bizde aldın diabetke shalınǵan, biraq h...</td>\n",
       "      <td>\"Теперь у нас есть четырёхмесячные мыши, у кот...</td>\n",
       "      <td>\"Hozir bizda diabetik bo'lishi kerak bo'lgan, ...</td>\n",
       "      <td>\"Házirde bizde diabetli bolıwı kerek bolǵan, d...</td>\n",
       "      <td>\"Hozir bizda ilgari diabetga chalingan, lekin ...</td>\n",
       "      <td>\"Biziń 4 aylıq tıshqanlarımızdıń bir waqıtları...</td>\n",
       "      <td>\"Endi bizde qant keselligi bolmaǵan tórt aylıq...</td>\n",
       "      <td>\"Now we have 4-month-old mice who were previou...</td>\n",
       "      <td>\"Сейчас у нас есть 4-месячные мыши, которые ра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Ehud Ur, professor of medicine at Dalhousi...</td>\n",
       "      <td>Jańa Shotlandiya, Galifaks qalasındaǵı Dalxauz...</td>\n",
       "      <td>Согласно предупреждению доктора Эхуда Ура (Ehu...</td>\n",
       "      <td>Yangi Shotlandiyaning Galifaks shahridagi Dalx...</td>\n",
       "      <td>Jańa Shotlandiyanıń Galifaks qalasındaǵı Dalxa...</td>\n",
       "      <td>Yangi Shotlandiya, Galifaks shahridagi Dalxauz...</td>\n",
       "      <td>Jańa Shotlandiyanıń Halifax qalasındaǵı Dalhou...</td>\n",
       "      <td>Jańa Shotlandiyanıń Galifaks qalasındaǵı Delxa...</td>\n",
       "      <td>Dr. Ehud Ur, professor of medicine at Dalhousi...</td>\n",
       "      <td>Доктор Эхуд Ур, профессор медицины Университет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Like some other experts, he is skeptical about...</td>\n",
       "      <td>Basqa qánigeler sıyaqlı, ol bul tabılǵan zatla...</td>\n",
       "      <td>Как и некоторые другие эксперты, он сомневаетс...</td>\n",
       "      <td>Ayrim boshqa mutaxassislar kabi, u diabetni da...</td>\n",
       "      <td>Ayırım basqa qánigeler sıyaqlı, ol diabetti em...</td>\n",
       "      <td>Boshqa mutaxassislar singari, u bu topilgan mo...</td>\n",
       "      <td>Basqa da qánigeler sıyaqlı ol qantlı diabetti ...</td>\n",
       "      <td>Basqa ayırım ekspertler sıyaqlı ol da diabetti...</td>\n",
       "      <td>Like other specialists, he was skeptical about...</td>\n",
       "      <td>Как и другие специалисты, он сомневался в возм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Monday, Sara Danius, permanent secretary of...</td>\n",
       "      <td>Dúyshembi kúni Shvetsiya akademiyası Ádebiyat ...</td>\n",
       "      <td>В понедельник Сара Даниус, постоянный секретар...</td>\n",
       "      <td>Dushanba kuni Shvetsiya Fanlar akademiyasi ada...</td>\n",
       "      <td>Dúyshembi kúni Shveciya Ilimler akademiyası ád...</td>\n",
       "      <td>Dushanba kuni Shvetsiya akademiyasi Adabiyot b...</td>\n",
       "      <td>Dúyshembi kúni Shveciya akademiyasınıń ádebiya...</td>\n",
       "      <td>Dúyshembi kúni Shveciya akademiyası janındaǵı ...</td>\n",
       "      <td>On Monday, the permanent secretary of the Swed...</td>\n",
       "      <td>В понедельник постоянный секретарь Нобелевског...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Danius said, \"Right now we are doing nothing. ...</td>\n",
       "      <td>Danius bılay dedi: \"Házir biz heshnárse islep ...</td>\n",
       "      <td>Даниус заявил: \"Сейчас мы ничего не делаем. Я ...</td>\n",
       "      <td>Danius \"Biz hozirda hech nima qilmayapmiz. Men...</td>\n",
       "      <td>Danius \"Biz házir hesh nárse islemey atırmız. ...</td>\n",
       "      <td>Danius shunday dedi: \"Hozir biz hech narsa qil...</td>\n",
       "      <td>- Házir bizler xesh nárse islemeymiz, - dedi D...</td>\n",
       "      <td>Danius bılay dedi: \"Biz házir hesh nárse islem...</td>\n",
       "      <td>Danius said, \"We're not doing anything right n...</td>\n",
       "      <td>Даниус сказал: \"Сейчас мы ничего не делаем. Я ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>As the areas are sparsely populated, and light...</td>\n",
       "      <td>Aymaqlar kem xalıq jasaytuǵınlıǵı hám jaqtılıq...</td>\n",
       "      <td>Так как эти районы являются малонаселенными, и...</td>\n",
       "      <td>Hududlarda aholi siyrakligi tufayli, yorug'lik...</td>\n",
       "      <td>Aymaqlarda xalıqtıń siyrekligi sebepli, jaqtıl...</td>\n",
       "      <td>Hududlar kam aholi yashaydiganligi va yorug'li...</td>\n",
       "      <td>Bul jerlerde xalıqtıń sanı az bolıwı hám jaqtı...</td>\n",
       "      <td>Sebebi bul rayonlarda xalıq az, sonıń ushın ja...</td>\n",
       "      <td>Because the regions are sparsely populated and...</td>\n",
       "      <td>Из-за малонаселенности регионов и того, что за...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Japanese work culture is more hierarchical and...</td>\n",
       "      <td>Yapon miynet mádeniyatı batıs táreplikler úyre...</td>\n",
       "      <td>Японская культура труда иерархичнее и формальн...</td>\n",
       "      <td>Yaponlarning ishlash madaniyati g'arbliklar od...</td>\n",
       "      <td>Yaponlardın islew mádeniyatı batıslılar ádetle...</td>\n",
       "      <td>Yapon mehnat madaniyati g'arbliklar o'rgangani...</td>\n",
       "      <td>YAponiyanıń miynet mádeniyatı batıs xalqına qa...</td>\n",
       "      <td>Yapon miynet mádeniyatı Batıs xalqı úyrengenin...</td>\n",
       "      <td>Japanese labor culture is more hierarchical an...</td>\n",
       "      <td>Японская культура труда скорее иерархична и фо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Suits are standard business attire, and cowork...</td>\n",
       "      <td>Kostyumlar standart jumıs kiyimi bolıp tabılad...</td>\n",
       "      <td>Костюмы являются стандартной деловой одеждой, ...</td>\n",
       "      <td>Kostyum-shimlar standart ish kiyimidir, hamkas...</td>\n",
       "      <td>Kostyum-shalbarlar standart jumis kiyimleri bo...</td>\n",
       "      <td>Kostyumlar standart ish kiyimi hisoblanadi va ...</td>\n",
       "      <td>Kostyumlar standart is kiyimleri bolıp, xızmet...</td>\n",
       "      <td>Kostyumlar standart is kiyimleri bolip, kásipl...</td>\n",
       "      <td>Costumes are standard workwear and colleagues ...</td>\n",
       "      <td>Костюмы являются стандартной рабочей одеждой, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>Workplace harmony is crucial, emphasizing grou...</td>\n",
       "      <td>Jumıs jayındaǵı uyqaslıq sheshiwshi áhmiyetke ...</td>\n",
       "      <td>Чрезвычайно важна гармония на рабочем месте, а...</td>\n",
       "      <td>Alohida shaxslarning yutuqlarini maqtashdan ko...</td>\n",
       "      <td>Ayırım shaxslardıń jetiskenliklerin maqtawdan ...</td>\n",
       "      <td>Ish joyidagi uyg'unlik hal qiluvchi ahamiyatga...</td>\n",
       "      <td>Jumıs ornındaǵı awızbirshilik ayrıqsha jetiske...</td>\n",
       "      <td>Jumıs ornındaǵı úylesiklilik oǵada áhmiyetli b...</td>\n",
       "      <td>Workplace harmony plays a decisive role, focus...</td>\n",
       "      <td>Совместимость на рабочем месте имеет решающее ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Workers must often get their superiors' approv...</td>\n",
       "      <td>Jumısshılar kóbinese ózleri qabıl etetuǵın hár...</td>\n",
       "      <td>Обычно работники должны получить разрешение на...</td>\n",
       "      <td>Ishshilar ko'pincha o'zlari qabiladigan har qa...</td>\n",
       "      <td>Jumisshilar kóbinese ózleriniń qáwimindegi hár...</td>\n",
       "      <td>Ishchilar ko'pincha o'zlari qabul qiladigan ha...</td>\n",
       "      <td>Xızmetkerler hár qanday qararı ushın basshılar...</td>\n",
       "      <td>Ádette xızmetkerler hár qanday qarar qabıl eti...</td>\n",
       "      <td>Workers often have to get their superiors' app...</td>\n",
       "      <td>Работники должны получать согласие своего нача...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               eng_Latn  \\\n",
       "0     \"We now have 4-month-old mice that are non-dia...   \n",
       "1     Dr. Ehud Ur, professor of medicine at Dalhousi...   \n",
       "2     Like some other experts, he is skeptical about...   \n",
       "3     On Monday, Sara Danius, permanent secretary of...   \n",
       "4     Danius said, \"Right now we are doing nothing. ...   \n",
       "...                                                 ...   \n",
       "1007  As the areas are sparsely populated, and light...   \n",
       "1008  Japanese work culture is more hierarchical and...   \n",
       "1009  Suits are standard business attire, and cowork...   \n",
       "1010  Workplace harmony is crucial, emphasizing grou...   \n",
       "1011  Workers must often get their superiors' approv...   \n",
       "\n",
       "                                               kaa_Latn  \\\n",
       "0     \"Házir bizde aldın diabetke shalınǵan, biraq h...   \n",
       "1     Jańa Shotlandiya, Galifaks qalasındaǵı Dalxauz...   \n",
       "2     Basqa qánigeler sıyaqlı, ol bul tabılǵan zatla...   \n",
       "3     Dúyshembi kúni Shvetsiya akademiyası Ádebiyat ...   \n",
       "4     Danius bılay dedi: \"Házir biz heshnárse islep ...   \n",
       "...                                                 ...   \n",
       "1007  Aymaqlar kem xalıq jasaytuǵınlıǵı hám jaqtılıq...   \n",
       "1008  Yapon miynet mádeniyatı batıs táreplikler úyre...   \n",
       "1009  Kostyumlar standart jumıs kiyimi bolıp tabılad...   \n",
       "1010  Jumıs jayındaǵı uyqaslıq sheshiwshi áhmiyetke ...   \n",
       "1011  Jumısshılar kóbinese ózleri qabıl etetuǵın hár...   \n",
       "\n",
       "                                               rus_Cyrl  \\\n",
       "0     \"Теперь у нас есть четырёхмесячные мыши, у кот...   \n",
       "1     Согласно предупреждению доктора Эхуда Ура (Ehu...   \n",
       "2     Как и некоторые другие эксперты, он сомневаетс...   \n",
       "3     В понедельник Сара Даниус, постоянный секретар...   \n",
       "4     Даниус заявил: \"Сейчас мы ничего не делаем. Я ...   \n",
       "...                                                 ...   \n",
       "1007  Так как эти районы являются малонаселенными, и...   \n",
       "1008  Японская культура труда иерархичнее и формальн...   \n",
       "1009  Костюмы являются стандартной деловой одеждой, ...   \n",
       "1010  Чрезвычайно важна гармония на рабочем месте, а...   \n",
       "1011  Обычно работники должны получить разрешение на...   \n",
       "\n",
       "                                               uzn_Latn  \\\n",
       "0     \"Hozir bizda diabetik bo'lishi kerak bo'lgan, ...   \n",
       "1     Yangi Shotlandiyaning Galifaks shahridagi Dalx...   \n",
       "2     Ayrim boshqa mutaxassislar kabi, u diabetni da...   \n",
       "3     Dushanba kuni Shvetsiya Fanlar akademiyasi ada...   \n",
       "4     Danius \"Biz hozirda hech nima qilmayapmiz. Men...   \n",
       "...                                                 ...   \n",
       "1007  Hududlarda aholi siyrakligi tufayli, yorug'lik...   \n",
       "1008  Yaponlarning ishlash madaniyati g'arbliklar od...   \n",
       "1009  Kostyum-shimlar standart ish kiyimidir, hamkas...   \n",
       "1010  Alohida shaxslarning yutuqlarini maqtashdan ko...   \n",
       "1011  Ishshilar ko'pincha o'zlari qabiladigan har qa...   \n",
       "\n",
       "                                      uzn_Latn-kaa_Latn  \\\n",
       "0     \"Házirde bizde diabetli bolıwı kerek bolǵan, d...   \n",
       "1     Jańa Shotlandiyanıń Galifaks qalasındaǵı Dalxa...   \n",
       "2     Ayırım basqa qánigeler sıyaqlı, ol diabetti em...   \n",
       "3     Dúyshembi kúni Shveciya Ilimler akademiyası ád...   \n",
       "4     Danius \"Biz házir hesh nárse islemey atırmız. ...   \n",
       "...                                                 ...   \n",
       "1007  Aymaqlarda xalıqtıń siyrekligi sebepli, jaqtıl...   \n",
       "1008  Yaponlardın islew mádeniyatı batıslılar ádetle...   \n",
       "1009  Kostyum-shalbarlar standart jumis kiyimleri bo...   \n",
       "1010  Ayırım shaxslardıń jetiskenliklerin maqtawdan ...   \n",
       "1011  Jumisshilar kóbinese ózleriniń qáwimindegi hár...   \n",
       "\n",
       "                                      kaa_Latn-uzn_Latn  \\\n",
       "0     \"Hozir bizda ilgari diabetga chalingan, lekin ...   \n",
       "1     Yangi Shotlandiya, Galifaks shahridagi Dalxauz...   \n",
       "2     Boshqa mutaxassislar singari, u bu topilgan mo...   \n",
       "3     Dushanba kuni Shvetsiya akademiyasi Adabiyot b...   \n",
       "4     Danius shunday dedi: \"Hozir biz hech narsa qil...   \n",
       "...                                                 ...   \n",
       "1007  Hududlar kam aholi yashaydiganligi va yorug'li...   \n",
       "1008  Yapon mehnat madaniyati g'arbliklar o'rgangani...   \n",
       "1009  Kostyumlar standart ish kiyimi hisoblanadi va ...   \n",
       "1010  Ish joyidagi uyg'unlik hal qiluvchi ahamiyatga...   \n",
       "1011  Ishchilar ko'pincha o'zlari qabul qiladigan ha...   \n",
       "\n",
       "                                      eng_Latn-kaa_Latn  \\\n",
       "0     \"Biziń 4 aylıq tıshqanlarımızdıń bir waqıtları...   \n",
       "1     Jańa Shotlandiyanıń Halifax qalasındaǵı Dalhou...   \n",
       "2     Basqa da qánigeler sıyaqlı ol qantlı diabetti ...   \n",
       "3     Dúyshembi kúni Shveciya akademiyasınıń ádebiya...   \n",
       "4     - Házir bizler xesh nárse islemeymiz, - dedi D...   \n",
       "...                                                 ...   \n",
       "1007  Bul jerlerde xalıqtıń sanı az bolıwı hám jaqtı...   \n",
       "1008  YAponiyanıń miynet mádeniyatı batıs xalqına qa...   \n",
       "1009  Kostyumlar standart is kiyimleri bolıp, xızmet...   \n",
       "1010  Jumıs ornındaǵı awızbirshilik ayrıqsha jetiske...   \n",
       "1011  Xızmetkerler hár qanday qararı ushın basshılar...   \n",
       "\n",
       "                                      rus_Cyrl-kaa_Latn  \\\n",
       "0     \"Endi bizde qant keselligi bolmaǵan tórt aylıq...   \n",
       "1     Jańa Shotlandiyanıń Galifaks qalasındaǵı Delxa...   \n",
       "2     Basqa ayırım ekspertler sıyaqlı ol da diabetti...   \n",
       "3     Dúyshembi kúni Shveciya akademiyası janındaǵı ...   \n",
       "4     Danius bılay dedi: \"Biz házir hesh nárse islem...   \n",
       "...                                                 ...   \n",
       "1007  Sebebi bul rayonlarda xalıq az, sonıń ushın ja...   \n",
       "1008  Yapon miynet mádeniyatı Batıs xalqı úyrengenin...   \n",
       "1009  Kostyumlar standart is kiyimleri bolip, kásipl...   \n",
       "1010  Jumıs ornındaǵı úylesiklilik oǵada áhmiyetli b...   \n",
       "1011  Ádette xızmetkerler hár qanday qarar qabıl eti...   \n",
       "\n",
       "                                      kaa_Latn-eng_Latn  \\\n",
       "0     \"Now we have 4-month-old mice who were previou...   \n",
       "1     Dr. Ehud Ur, professor of medicine at Dalhousi...   \n",
       "2     Like other specialists, he was skeptical about...   \n",
       "3     On Monday, the permanent secretary of the Swed...   \n",
       "4     Danius said, \"We're not doing anything right n...   \n",
       "...                                                 ...   \n",
       "1007  Because the regions are sparsely populated and...   \n",
       "1008  Japanese labor culture is more hierarchical an...   \n",
       "1009  Costumes are standard workwear and colleagues ...   \n",
       "1010  Workplace harmony plays a decisive role, focus...   \n",
       "1011  Workers often have to get their superiors' app...   \n",
       "\n",
       "                                      kaa_Latn-rus_Cyrl  \n",
       "0     \"Сейчас у нас есть 4-месячные мыши, которые ра...  \n",
       "1     Доктор Эхуд Ур, профессор медицины Университет...  \n",
       "2     Как и другие специалисты, он сомневался в возм...  \n",
       "3     В понедельник постоянный секретарь Нобелевског...  \n",
       "4     Даниус сказал: \"Сейчас мы ничего не делаем. Я ...  \n",
       "...                                                 ...  \n",
       "1007  Из-за малонаселенности регионов и того, что за...  \n",
       "1008  Японская культура труда скорее иерархична и фо...  \n",
       "1009  Костюмы являются стандартной рабочей одеждой, ...  \n",
       "1010  Совместимость на рабочем месте имеет решающее ...  \n",
       "1011  Работники должны получать согласие своего нача...  \n",
       "\n",
       "[1012 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27bf46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('results/test/tilmoch.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8f847-454d-45d9-90b4-f8bccecd31a3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87725401-9f9b-41fc-abe8-92e6cfca7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import sacrebleu\n",
    "\n",
    "tutuq_sub = re.compile(r\"([\\u02BB\\u02BC\\u2018\\u2019\\u0060\\u00B4])\", re.UNICODE | re.IGNORECASE)\n",
    "\n",
    "def normalize_apostrophes(text):\n",
    "    text = re.sub(tutuq_sub, \"'\", text)\n",
    "    return text\n",
    "\n",
    "def calculate_scores(df, src_col, tgt_col):\n",
    "    bleu_calc = sacrebleu.BLEU()\n",
    "    chrf_calc = sacrebleu.CHRF(word_order=2)\n",
    "\n",
    "    df = df.dropna(subset=[src_col, tgt_col], ignore_index=True)\n",
    "    \n",
    "    src_sents = df[src_col].tolist()\n",
    "    tgt_sents = df[tgt_col].tolist()\n",
    "    \n",
    "    src_sents = [normalize_apostrophes(sent) for sent in src_sents]\n",
    "    tgt_sents = [normalize_apostrophes(sent) for sent in tgt_sents]\n",
    "\n",
    "    bleu = bleu_calc.corpus_score(tgt_sents, [src_sents])\n",
    "    chrf = chrf_calc.corpus_score(tgt_sents, [src_sents])\n",
    "    \n",
    "    return f'{bleu.score:.3f} / {chrf.score:.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc05e078-dbeb-4c28-a592-db7e50fff9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['apertium-uzb-kaa.csv',\n",
    " 'from-to.uz.csv',\n",
    " 'google-from_kaz.csv',\n",
    " 'google-from_uzb.csv',\n",
    " 'madlad-400.csv',\n",
    " 'nllb-200-distilled-600M-from_kaz.csv',\n",
    " 'nllb-200-distilled-600M-from_uzb.csv',\n",
    " 'dilmash-600M.csv',\n",
    " 'dilmash-600M-til.csv',\n",
    " 'claude-3-5-sonnet.csv',\n",
    " 'tilmoch.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results_dev = []\n",
    "results_test = []\n",
    "\n",
    "# Process each CSV file\n",
    "for file in csv_files:\n",
    "    # df_dev = pd.read_csv(f'results/dev/{file}')\n",
    "    df_test = pd.read_csv(f'results/test/{file}')\n",
    "    \n",
    "    # Find columns with dash (language pairs)\n",
    "    # lang_pairs_dev = [col for col in df_dev.columns if '-' in col]\n",
    "    lang_pairs_test = [col for col in df_test.columns if '-' in col]\n",
    "    \n",
    "    # Calculate scores for each language pair\n",
    "    # file_results_dev = {'translation_model': file.replace('.csv', '')}\n",
    "    # for pair in lang_pairs_dev:\n",
    "    #     src_lang, tgt_lang = pair.split('-')\n",
    "    #     scores = calculate_scores(df_dev, tgt_lang, pair)\n",
    "    #     file_results_dev[pair] = scores\n",
    "    \n",
    "    # results_dev.append(file_results_dev)\n",
    "\n",
    "    file_results_test = {'translation_model': file.replace('.csv', '')}\n",
    "    for pair in lang_pairs_test:\n",
    "        src_lang, tgt_lang = pair.split('-')\n",
    "        scores = calculate_scores(df_test, tgt_lang, pair)\n",
    "        file_results_test[pair] = scores\n",
    "    \n",
    "    results_test.append(file_results_test)\n",
    "\n",
    "col_order = ['translation_model', 'eng_Latn-kaa_Latn', 'rus_Cyrl-kaa_Latn',\n",
    "             'uzn_Latn-kaa_Latn', 'kaa_Latn-eng_Latn',  'kaa_Latn-rus_Cyrl',\n",
    "             'kaa_Latn-uzn_Latn',]\n",
    "\n",
    "# scores_df_dev = pd.DataFrame(results_dev)[col_order]\n",
    "# scores_df_dev = scores_df_dev.fillna('-')\n",
    "\n",
    "scores_df_test = pd.DataFrame(results_test)[col_order]\n",
    "scores_df_test = scores_df_test.fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebc768f2-9ab6-41af-adc4-71895af45713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation_model</th>\n",
       "      <th>eng_Latn-kaa_Latn</th>\n",
       "      <th>rus_Cyrl-kaa_Latn</th>\n",
       "      <th>uzn_Latn-kaa_Latn</th>\n",
       "      <th>kaa_Latn-eng_Latn</th>\n",
       "      <th>kaa_Latn-rus_Cyrl</th>\n",
       "      <th>kaa_Latn-uzn_Latn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apertium-uzb-kaa</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>12.264 / 42.272</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>5.609 / 35.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from-to.uz</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>20.176 / 53.224</td>\n",
       "      <td>8.238 / 25.731</td>\n",
       "      <td>-</td>\n",
       "      <td>11.182 / 41.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google-from_kaz</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>20.945 / 44.631</td>\n",
       "      <td>13.549 / 36.905</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google-from_uzb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>21.399 / 45.496</td>\n",
       "      <td>13.776 / 37.641</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>madlad-400</td>\n",
       "      <td>2.677 / 22.474</td>\n",
       "      <td>2.011 / 19.934</td>\n",
       "      <td>1.305 / 16.809</td>\n",
       "      <td>28.418 / 53.059</td>\n",
       "      <td>16.942 / 41.120</td>\n",
       "      <td>10.256 / 38.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nllb-200-distilled-600M-from_kaz</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4.321 / 23.349</td>\n",
       "      <td>3.117 / 16.864</td>\n",
       "      <td>3.910 / 25.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nllb-200-distilled-600M-from_uzb</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.892 / 32.256</td>\n",
       "      <td>5.822 / 26.333</td>\n",
       "      <td>4.828 / 29.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dilmash-600M</td>\n",
       "      <td>12.312 / 42.224</td>\n",
       "      <td>10.724 / 40.290</td>\n",
       "      <td>16.130 / 48.418</td>\n",
       "      <td>28.747 / 53.700</td>\n",
       "      <td>15.688 / 41.582</td>\n",
       "      <td>18.517 / 51.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dilmash-600M-til</td>\n",
       "      <td>15.018 / 45.433</td>\n",
       "      <td>12.001 / 42.070</td>\n",
       "      <td>17.592 / 49.902</td>\n",
       "      <td>32.072 / 56.449</td>\n",
       "      <td>17.527 / 43.515</td>\n",
       "      <td>19.832 / 52.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>claude-3-5-sonnet</td>\n",
       "      <td>11.170 / 33.373</td>\n",
       "      <td>9.015 / 34.016</td>\n",
       "      <td>12.742 / 35.173</td>\n",
       "      <td>37.059 / 61.405</td>\n",
       "      <td>25.697 / 51.230</td>\n",
       "      <td>22.378 / 54.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tilmoch</td>\n",
       "      <td>22.780 / 53.669</td>\n",
       "      <td>15.098 / 46.852</td>\n",
       "      <td>20.031 / 52.562</td>\n",
       "      <td>34.787 / 58.817</td>\n",
       "      <td>21.620 / 47.029</td>\n",
       "      <td>22.440 / 55.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   translation_model eng_Latn-kaa_Latn rus_Cyrl-kaa_Latn  \\\n",
       "0                   apertium-uzb-kaa                 -                 -   \n",
       "1                         from-to.uz                 -                 -   \n",
       "2                    google-from_kaz                 -                 -   \n",
       "3                    google-from_uzb                 -                 -   \n",
       "4                         madlad-400    2.677 / 22.474    2.011 / 19.934   \n",
       "5   nllb-200-distilled-600M-from_kaz                 -                 -   \n",
       "6   nllb-200-distilled-600M-from_uzb                 -                 -   \n",
       "7                       dilmash-600M   12.312 / 42.224   10.724 / 40.290   \n",
       "8                   dilmash-600M-til   15.018 / 45.433   12.001 / 42.070   \n",
       "9                  claude-3-5-sonnet   11.170 / 33.373    9.015 / 34.016   \n",
       "10                           tilmoch   22.780 / 53.669   15.098 / 46.852   \n",
       "\n",
       "   uzn_Latn-kaa_Latn kaa_Latn-eng_Latn kaa_Latn-rus_Cyrl kaa_Latn-uzn_Latn  \n",
       "0    12.264 / 42.272                 -                 -    5.609 / 35.823  \n",
       "1    20.176 / 53.224    8.238 / 25.731                 -   11.182 / 41.367  \n",
       "2                  -   20.945 / 44.631   13.549 / 36.905                 -  \n",
       "3                  -   21.399 / 45.496   13.776 / 37.641                 -  \n",
       "4     1.305 / 16.809   28.418 / 53.059   16.942 / 41.120   10.256 / 38.749  \n",
       "5                  -    4.321 / 23.349    3.117 / 16.864    3.910 / 25.260  \n",
       "6                  -    8.892 / 32.256    5.822 / 26.333    4.828 / 29.683  \n",
       "7    16.130 / 48.418   28.747 / 53.700   15.688 / 41.582   18.517 / 51.027  \n",
       "8    17.592 / 49.902   32.072 / 56.449   17.527 / 43.515   19.832 / 52.575  \n",
       "9    12.742 / 35.173   37.059 / 61.405   25.697 / 51.230   22.378 / 54.707  \n",
       "10   20.031 / 52.562   34.787 / 58.817   21.620 / 47.029   22.440 / 55.106  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f440b649-2ae6-4e7a-8076-1d8b9d909833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_df_dev.to_csv('results/results_dev.csv', index=False)\n",
    "scores_df_test.to_csv('results/results_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065b133-d49c-4cad-8204-fdc6b775669d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
